---
layout: post
title: 빅데이터를 지탱하는 기술 summary
date: 2022-10-20 15:30:00
description: 핵심 키워드 및 개념 복습
---

# 0. 서문
<br>

- data discovery : 데이터 검색. 시각화 기법. 프로젝트 단위로 데이터를 살필 때 사용. 

- mpp database : massive parallel processing. 대규모 병렬 프로세스 데이터베이스. 하나의 쿼리를 여러 개의 프로세스로 병렬처리.

- 웹 액세스 분석 : 디지털 마케팅 업계에서 고객 행동분석부터 인터넷 광고 전달에 이르기까지 다양한 용도로 웹 액세스 로그 활용. 특정 산업에 특화된 빅데이터 기술 활용 분석.

- 실시간 메시지 전달 : message delivery

- 중복 제거 : deduplication

- 분산 스토리지 : distributed storage
<br>
<br>

### 0-1. 구성
<br>
1장 : 빅데이터 기술의 배경, 스몰데이터 기술, 간단한 파이썬 스크립트, data discovery
<br>
<br>
2장~5장: 빅데이터 시스템 구성 기술. 데이터 시각화를 하나의 과제로 설정해 기술 설명
<br>
<br>
2장 : 빅데이터 검색. 데이터의 대화적인 집계와 시각화. 데이터를 초 단위로 집계하기 위한 데이터 마트(data mart)
<br>
<br>
3장 : 빅데이터의 분산처리. Hadoop, Spark 등 분산처리 프레임워크 사용 -> 데이터 가공/집계 -> 데이터 마트 생성.
<br>
<br>
4장 : 빅데이터의 축적. 데이터를 수집해서 보존하는 절차. 수백만 대의 센서로부터 데이터 수집시 db에 쓰는 것으로도 부하 걸림. 이를 분산 스토리지에 넣는 '데이터 수집(data ingestion)'에 대해 설명.
<br>
<br>
5장 : 빅데이터의 파이프라인. 데이터 처리 자동화하기. 정기적 스케줄링(배치 처리), 끊임없이 실행(스트림 처리). 워크플로 관리의 사고 방법.
<br>
<br>
6장 : 빅데이터 분석 기반의 구축. twitter의 트윗 집계 예제 프로그램. 클라우드 이용에 대해.
<br>
기초 : spark로 대화적 세션으로 데이터 분석
응용 : 데이터 처리 자동화. 워크플로 관리 소프트웨어로 airflow 도입, 매일 한 번씩 데이터 마트 업데이트하는 배치 처리 실행

<br>
<br>

---
# 1. 빅데이터의 기초 지식

- ~2011년 : hadoop, NoSQL 데이터베이스 발전
- 2012년 : 클라우드 방식의 DW, BI 도구 보급
- 2013년~ : 스트림 처리, AdHoc 분석 환경 확충

<br>
<br>

데이터 분석 방법, 데이터 처리 시간 단축


internet  -> RDB, NoSQL, Text Data -> Hadoop

- Hadoop : 다수의 컴퓨터에서 대량의 데이터를 처리하기 위한 시스템. 구글의 분산처리 프레임워크인 MapReduce를 참고해 제작. 
Hive를 통해 SQL 쿼리를 하둡에서 실행가능해진 뒤로 프로그래밍 없이 데이터 집계 가능. 
<br>
<br>

- NoSQL : 키 밸류 스토어(다수의 키와 값을 관련지어 저장), 도큐멘트 스토어(JSON과 같은 복잡한 데이터 구조 저장), 와이드 칼럼 스토어(여러 키를 사용하여 높은 확장성 제공)
<br>
<br>
MongoDB : 도큐먼트 스토어
<br>
CouchDB : 도큐먼트 스토어
<br>
Riak : 키밸류 스토어
<br>
Cassandra : 와이드 칼럼 스토어
<br>
Redis : 키밸류 스토어
<br>
<br>

데이터 처리를 위한 클라우드 서비스
- Amazon Elastic MapReduce : 클라우드를 위한 hadoop
- 구글 BigQuery : DW
- Azure HDInsight : 클라우드를 위한 hadoop
- Amazon Redshift : DW
<br>
<br>

데이터 규모 판단
<br>
스몰데이터 : 백만 ~ 천만 로우. 수GB
<br>
<br>

데이터 디스커버리 ~= BI
<br>
BI : DW와 조합해 사용한 경영자용 시각화 시스템

<br>
<br>

데이터 전송 방법
- 벌크형(bulk): 정기적으로 데이터를 수집할 때 사용
- 스트림형(streaming): 차례차례 생성되는 데이터를 끊임없이 계속해서 보낼 때 사용

<br>

---
# 2. 빅데이터의 탐색

데이터 집계
- SQL : datalake -> datamart, 대량의 데이터 먼저 한번 집계, 라인 수 축소(수만~수억 레코드), 데이터 집계 프로세스
- 시각화도구 : datamart -> dashboards, cross table, 5~100 항목 시각화, 시각화 프로세스 
<br>
<br>


테이블 종횡 변환
- SQL : 할 수 있는데 각 칼럼마다 반복해야 해서 번거로움
- pandas : 피벗, 언피벗이 더 원활함, df로 조작, 언피벗(df.melt 사용)
<br>
<br>

3계층 데이터 집계 시스템
- datalake -(데이터 집계, 수분~수시간) -> 데이터마트 -(크로스집계, 수초)-> 시각화도구
<br>
<br>

데이터 처리의 지연-lantency
- RDB(MySQL, PostgreSQL) : 천만 레코드(5GB) 정도라면 일반적 RDB에 저장, 지연 적고 많은 수의 클라이언트 동시 접속해도 성능 나빠지지 않기 때문에 데이터마트로 적합, but 메모리 부족하면 성능 급격히 나빠짐, 수억 레코드 초과하는 집계는 디바이스 I/O가 발생
- MPP(massive parallel processing) : 압축과 분산. 대규모 병렬 처리. 데이터 집계 최적화, DW와 Data Analysis용 DB에서 많이 사용, Amazon Redshift, Google BigQuery 등.
<br>
<br>

열 지향 디비 접근
- RDB(MySQL, Oracle)는 행 지향 데이터베이스
- 데이터분석에 사용되는 데이터베이스는 칼럼 단위 집계 최적화. 열 지향 데이터베이스. 예) 테라데이터, Amazon Redshift
<br>
<br>

데이터 처리 성능
- 처리량(throughput) : 일정 시간에 처리할 수 있는 데이터의 양, 배치 처리 등 대규모 데이터 처리에서 중요시
- 대기시간(지연) : 데이터 처리가 끝날 떄까지의 대기 시간, 애드 혹 데이터분석 등에서 중시
- DW나 Datalake는 대량의 데이터를 처리하기 위해 **처리량**을 중시
- 데이터마트는 **지연시간**의 단축이 요구됨. 충분한 메모리와 디스크 I/O 절감 필요
<br>
<br>

데이터마트에 사용되는 주요 기술
- RDB : 행 지향, 적정 레코드 수(~수천만)
- MPP 데이터베이스 : 열 지향, 적정 레코드 수(수억~)
- 대화형 쿼리 엔진 : 열 지향, 적정 레코드 수(수억~)
<br>
<br>


데이터 시각화
- 애드혹 분석 : 주피터 노트북, 그때마다 수동으로 하되 기민하게 분석 가능
- 대시보드 도구 : 정기적으로 집계 결과 필요할 때, BI도구 활용. 예) Redash, Superset, Kibana(실시간 시각화)
<br>
<br>

성능과의 균형 고려
- 데이터 마트 : 안정적 성능 중요
- 데이터 웨어하우스 : 대량 데이터 처리 중요
<br>
<br>

### 데이터마트는 비정규화 테이블로

### DW는 스타스키마가 성능 우수
<br>
<br>

---
# 3. 빅데이터의 분산 처리
<br>
<br>

Hadoop에서 사용할 수 있는 열 지향 스토리지
- Apache ORC : 구조화 데이터를 위한 열 지향 스토리지, 처음에 스키마 정한 후 데이터 저장
- Apache Parquet : 스키마리스에 가까운 데이터 구조, JSON 같은 뒤얽힌 데이터도 그대로 저장 가능
















